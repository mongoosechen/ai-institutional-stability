# AI Governance — Diagnostic Notes

This repository contains a small set of **exploratory diagnostic notes** on AI governance, institutional risk, and responsibility allocation under automation.

These notes are part of a **larger, ongoing research system** and are shared here in a deliberately partial form. They are not intended as policy proposals, legal recommendations, or normative arguments. Their purpose is to surface structural mechanisms that often remain implicit in discussions of AI deployment and governance.

The notes focus on how AI systems interact with existing institutional structures, particularly around discretion, ambiguity, buffering capacity, and responsibility attribution.

---

## Scope and intent

The materials in this repository are:

- **Diagnostic, not prescriptive**  
- **Mechanism-focused, not solution-oriented**  
- **Exploratory, not comprehensive**  

They aim to clarify *why* certain AI deployments generate downstream legal or governance stress even when systems are technically robust or formally compliant.

They are written to be legible to researchers and practitioners in AI governance, law, and institutional risk analysis, without requiring familiarity with the broader research system they originate from.

---

## Notes

### 1. Structural Misalignment in AI Governance Across Institutional Systems  
Examines why similar AI systems can stabilize some institutions while destabilizing others, depending on how discretion, ambiguity, and authority are structurally handled.

### 2. When Automation Removes Buffers: Risk Migration in Institutional Decision-Making  
Identifies informal human buffering as a stabilizing function and traces how institutional risk migrates when automation removes these roles without structural replacement.

### 3. Responsibility Without Authority: Attribution Gaps in AI-Mediated Decisions  
Analyzes how AI systems can increase responsibility density at the operational level without increasing corresponding authority, producing persistent attribution and liability gaps.

---

## What this repository is not

This repository does **not**:
- advocate for specific governance regimes,
- argue for or against particular AI technologies,
- present a unified theory of AI governance,
- or take a position on national or geopolitical actors.

Any such interpretations should be treated as outside the scope of these notes.

---

## Status

These documents are shared as **working research artifacts**.  
They may evolve, be superseded, or be withdrawn as the broader research program develops.

They are published here to support discussion, critique, and further inquiry—not as finished conclusions.
